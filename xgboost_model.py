import os
import torch
import pickle
import numpy as np
import xgboost as xgb
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_extraction.text import TfidfVectorizer

def tf_idf(groups):
    all_data = []
    for g in groups:
        files = os.listdir("API Sequence/" + g)
        for file_name in files:
            path = "API Sequence/" + g + "/" + file_name
            with open(path, 'rb') as f:
                seq = pickle.load(f)
            if seq:
                all_data.append(' '.join(seq))
                del seq
    print(f"The number of all data is: {len(all_data)}")
    vectorizer = TfidfVectorizer(ngram_range=(1, 3))
    feats = vectorizer.fit_transform(all_data)
    print(f"The shape of all feats is: {feats.shape}")
    return feats


def run(groups, feats, labels):
    labels = np.asarray(labels)
    meta_train = np.zeros(shape=(len(labels), len(groups)))
    all = []
    skf = StratifiedKFold(n_splits=5, random_state=3, shuffle=True)
    for i, (tra_idx, val_idx) in enumerate(skf.split(feats, labels)):
        x_train, y_train = feats[tra_idx], labels[tra_idx]
        x_val, y_val = feats[val_idx], labels[val_idx]
        print("Fold: {}".format(str(i)))
        print(len(tra_idx), len(val_idx))
        dtrain = xgb.DMatrix(x_train, label=y_train)
        dval = xgb.DMatrix(x_val, y_val)
        param = {'max_depth': 6,
                 'eta': 0.08,
                 'eval_metric': 'mlogloss',
                 'objective': 'multi:softprob',
                 'num_class': len(groups),
                 'subsample': 0.8,
                 'colsample_bytree': 0.85}
        evallist = [(dtrain, 'train'), (dval, 'val')]
        num_rounds = 100
        bst = xgb.train(param, dtrain, num_rounds, evals=evallist, early_stopping_rounds=50)
        pred_val = bst.predict(dval)
        meta_train[val_idx] += pred_val
        all += val_idx.tolist()

    output = torch.tensor(meta_train)
    target = torch.tensor(labels)
    result = torch.max(output, 1)[1]
    corrects = (result.data == target.data).sum()
    print(f"Accuracy: {corrects / len(labels)}")


if __name__ == "__main__":
    apt_groups = ["APT 1", "APT 10", "APT 29", "APT 30", "Dark Hotel", "Gorgon Group", "Winnti"]
    labels = [0]*252 + [1]*159 + [2]*128 + [3]*149 + [4]*196 + [5]*208 + [6]*162
    feats = tf_idf(apt_groups)
    run(apt_groups, feats, labels)